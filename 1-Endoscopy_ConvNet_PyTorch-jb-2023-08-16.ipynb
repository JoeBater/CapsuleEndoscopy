{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() == True else 'cpu')\n",
    "device\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Erosion', 'Ampulla of Vater', 'adenomatous', 'Lymphangiectasia', 'hyperplastic', 'Blood - hematin', 'Erythema', 'Pylorus', 'Normal clean mucosa', 'missing', 'Angiectasia', 'Reduced Mucosal View', 'Ileocecal valve', 'Ulcer', 'Foreign Body', 'Blood - fresh')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Erosion': 0,\n",
       " 'Ampulla of Vater': 1,\n",
       " 'adenomatous': 2,\n",
       " 'Lymphangiectasia': 3,\n",
       " 'hyperplastic': 4,\n",
       " 'Blood - hematin': 5,\n",
       " 'Erythema': 6,\n",
       " 'Pylorus': 7,\n",
       " 'Normal clean mucosa': 8,\n",
       " 'missing': 9,\n",
       " 'Angiectasia': 10,\n",
       " 'Reduced Mucosal View': 11,\n",
       " 'Ileocecal valve': 12,\n",
       " 'Ulcer': 13,\n",
       " 'Foreign Body': 14,\n",
       " 'Blood - fresh': 15}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_path = r'C:\\Users\\user\\ML\\endoscopy\\kvasir-capsule'\n",
    "# train_df = pd.read_csv(img_path+'/train.csv')\n",
    "# validate_df = pd.read_csv(img_path+'/validation.csv')\n",
    "# test_df = pd.read_csv(img_path+'/test.csv')\n",
    "\n",
    "# img_path = r'C:\\Users\\user\\ML\\endoscopy\\kvasir-capsule-augments'\n",
    "# train_df = pd.read_csv(img_path+'/train_augment_polyp.csv')\n",
    "# validate_df = pd.read_csv(img_path+'/validation_augment_polyp.csv')\n",
    "# test_df = pd.read_csv(img_path+'/test_augment_polyp.csv')\n",
    "\n",
    "# img_path = r'C:\\Users\\user\\ML\\endoscopy\\kvasir-capsule-augments'\n",
    "# train_df = pd.read_csv(img_path+'/train_augment_polyp_40.csv')\n",
    "# validate_df = pd.read_csv('C:/Users/user/ML/endoscopy/kvasir-capsule/validation.csv')\n",
    "# test_df = pd.read_csv('C:/Users/user/ML/endoscopy/kvasir-capsule/test.csv')\n",
    "\n",
    "img_path = r'C:\\Users\\user\\ML\\endoscopy\\train_validation_test_sets'\n",
    "train_df = pd.read_excel(img_path+'/kvasir-polyps-combined_set1.xlsx', sheet_name='train')\n",
    "#validate_df = pd.read_excel(img_path+'/kvasir-polyps-combined_set1.xlsx', sheet_name='validate')\n",
    "validate_df = pd.read_csv(img_path+'/kvasir-polyps-combined_val_balanced200.csv')\n",
    "test_df = pd.read_excel(img_path+'/kvasir-polyps-combined_set1.xlsx', sheet_name='test')\n",
    "\n",
    "classes = tuple(set(train_df['label']))\n",
    "print(classes)\n",
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal clean mucosa     24680\n",
       "adenomatous             16798\n",
       "Ileocecal valve         15103\n",
       "hyperplastic            15093\n",
       "Reduced Mucosal View    10448\n",
       "Pylorus                  5535\n",
       "Angiectasia              3121\n",
       "Ulcer                    3050\n",
       "Foreign Body             2786\n",
       "Lymphangiectasia         2139\n",
       "Erosion                  1822\n",
       "missing                  1746\n",
       "Blood - fresh            1605\n",
       "Erythema                  571\n",
       "Blood - hematin            45\n",
       "Ampulla of Vater           38\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_size = (229*229)\n",
    "num_classes = len(classes)\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7420\\3643289931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvgg16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'VGG16_Weights.DEFAULT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnum_ftrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m229\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m229\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1614\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "num_ftrs = vgg16.fc.in_features\n",
    "vgg16.fc = nn.Linear(num_ftrs, len(classes))\n",
    "summary(vgg16,(3,229,229))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "     ])\n",
    "\n",
    "# mean and std dev of imagenet are - Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = []\n",
    "train_image_labels = []\n",
    "train_image_classes = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    train_image_paths.append(train_df.loc[i,'filename'])\n",
    "    train_image_labels.append(train_df.loc[i,'label'])\n",
    "    train_image_classes.append(class_to_idx[train_df.loc[i,'label']])\n",
    "\n",
    "validate_image_paths = []\n",
    "validate_image_labels = []\n",
    "validate_image_classes = []\n",
    "\n",
    "for i in range(len(validate_df)):\n",
    "    validate_image_paths.append(validate_df.loc[i,'filename'])\n",
    "    validate_image_labels.append(validate_df.loc[i,'label'])\n",
    "    validate_image_classes.append(class_to_idx[validate_df.loc[i,'label']])\n",
    "\n",
    "test_image_paths = []\n",
    "test_image_labels = []\n",
    "test_image_classes = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    test_image_paths.append(test_df.loc[i,'filename'])\n",
    "    test_image_labels.append(test_df.loc[i,'label'])\n",
    "    test_image_classes.append(class_to_idx[test_df.loc[i,'label']])\n",
    "    \n",
    "# for i in range(len(train_image_paths)):\n",
    "#     print(train_image_paths[i] + ' - ' + train_image_labels[i] + ' - ' + str(train_image_classes[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndoscopyDataset(Dataset):\n",
    "    def __init__(self, image_paths, image_classes, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.image_classes = image_classes\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_path = self.image_paths[idx]\n",
    "        #print(image_path)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        dim = (229, 229)\n",
    "        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        label = self.image_classes[idx]\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = EndoscopyDataset(train_image_paths,train_image_classes,transform)\n",
    "validate_dataset = EndoscopyDataset(validate_image_paths,validate_image_classes,transform) \n",
    "test_dataset = EndoscopyDataset(test_image_paths,test_image_classes,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['Epoch', 'Loss', 'accuracy training', 'accuracy validation'])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(validate_dataset, batch_size=batch_size, shuffle=True)\n",
    " \n",
    "class EndoscopyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    " \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    " \n",
    "        self.flat = nn.Flatten()\n",
    " \n",
    "        self.fc3 = nn.Linear(831744, 512)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    " \n",
    "        self.fc4 = nn.Linear(512, len(classes))\n",
    " \n",
    "    def forward(self, x):\n",
    "        # input 3x229x229, output 32x229x229\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.drop1(x)\n",
    "        # input 32x229x229, output 63x229x229\n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 64x229x229, output 64x114x114\n",
    "        x = self.pool2(x)\n",
    "        # input 64x114x114, output 831744\n",
    "        x = self.flat(x)\n",
    "        # input 831744, output 512\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.drop3(x)\n",
    "        # input 512, output 10\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    " \n",
    "\n",
    "model = vgg16 #EndoscopyModel()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        #print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples)}')\n",
    "        \n",
    "    return float(num_correct) / float(num_samples)\n",
    "\n",
    "# train network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(trainloader):\n",
    "        \n",
    "        # get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    train_accuracy = check_accuracy(trainloader, model)\n",
    "    validation_accuracy = check_accuracy(testloader, model)\n",
    "    print(f'{epoch}, {sum(losses)/len(losses)}, {train_accuracy}, {validation_accuracy}')\n",
    "    \n",
    "    df_results = pd.concat([df_results,\n",
    "                           pd.DataFrame({'Epoch':epoch, 'Loss': losses, 'accuracy training':train_accuracy, \n",
    "                                         'accuracy validation':validation_accuracy})], ignore_index=True)\n",
    "\n",
    "        \n",
    "model.train()\n",
    "    \n",
    "print('checking accuracy on the training set', check_accuracy(trainloader, model))\n",
    "\n",
    "print('checking accuracy on the test set', check_accuracy(testloader, model))\n",
    "\n",
    "torch.save(model.state_dict(), \"endoscopymodel_testset1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(n_epochs):\n",
    "#     for image, label in trainloader:\n",
    "#         # forward, backward, and then weight update\n",
    "#         y_pred = model(image)\n",
    "#         loss = loss_fn(y_pred, label)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    " \n",
    "#     acc = 0\n",
    "#     count = 0\n",
    "#     for image, label in testloader:\n",
    "#         y_pred = model(image)\n",
    "#         acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
    "#         count += len(labels)\n",
    "#     acc /= count\n",
    "#     print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('checking accuracy on the training set', check_accuracy(trainloader, model))\n",
    "\n",
    "print('checking accuracy on the test set', check_accuracy(testloader, model))\n",
    "\n",
    "torch.save(model.state_dict(), \"endoscopymodel_testset_64_8epochs_valbal_imagenetnorm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df_results['Epoch'], df_results['accuracy training'], color='green', marker='o', linestyle='dashed', linewidth=1, markersize=4, label='training')\n",
    "plt.plot(df_results['Epoch'], df_results['accuracy validation'], color='blue', marker='o', linestyle='dashed', linewidth=1, markersize=4, label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
